{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "203b0eed",
   "metadata": {},
   "source": [
    "# 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5693ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv,find_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a772fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3489238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../LLM/data_base/knowledge_db/1. 简介.md\n",
      "../LLM/data_base/knowledge_db/pumpkin_book.pdf\n",
      "../LLM/data_base/knowledge_db/prompt_engineering\\1. 简介 Introduction.md\n",
      "../LLM/data_base/knowledge_db/prompt_engineering\\2. 提示原则 Guidelines.md\n",
      "../LLM/data_base/knowledge_db/prompt_engineering\\3. 迭代优化 Iterative.md\n",
      "../LLM/data_base/knowledge_db/prompt_engineering\\4. 文本概括 Summarizing.md\n",
      "../LLM/data_base/knowledge_db/prompt_engineering\\5. 推断 Inferring.md\n",
      "../LLM/data_base/knowledge_db/prompt_engineering\\6. 文本转换 Transforming.md\n",
      "../LLM/data_base/knowledge_db/prompt_engineering\\7. 文本扩展 Expanding.md\n",
      "../LLM/data_base/knowledge_db/prompt_engineering\\8. 聊天机器人 Chatbot.md\n",
      "../LLM/data_base/knowledge_db/prompt_engineering\\9. 总结 Summary.md\n",
      "../LLM/data_base/knowledge_db/prompt_engineering\\readme.md\n"
     ]
    }
   ],
   "source": [
    "file_paths = []\n",
    "folder_path = '../LLM/data_base/knowledge_db/'\n",
    "# for root,dirs,files in os.walk(folder_path):\n",
    "#     if root == folder_path:\n",
    "#         continue\n",
    "#     else:\n",
    "#         for file in files:\n",
    "#             file_path = os.path.join(root,file)\n",
    "#             file_paths.append(file_path)\n",
    "\n",
    "for root,dirs,files in os.walk(folder_path):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root,file)\n",
    "        file_paths.append(file_path)\n",
    "for file in file_paths:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f833eda8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../LLM/data_base/knowledge_db/\n",
      "--------\n",
      "['prompt_engineering']\n",
      "--------\n",
      "['1. 简介.md', 'pumpkin_book.pdf']\n",
      "***********\n",
      "../LLM/data_base/knowledge_db/prompt_engineering\n",
      "--------\n",
      "[]\n",
      "--------\n",
      "['1. 简介 Introduction.md', '2. 提示原则 Guidelines.md', '3. 迭代优化 Iterative.md', '4. 文本概括 Summarizing.md', '5. 推断 Inferring.md', '6. 文本转换 Transforming.md', '7. 文本扩展 Expanding.md', '8. 聊天机器人 Chatbot.md', '9. 总结 Summary.md', 'readme.md']\n",
      "***********\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "for root,dirs,files in os.walk(folder_path):\n",
    "    print(root,dirs,files,sep = \"\\n--------\\n\")\n",
    "    print(\"***********\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0efbfc89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      " 是 OpenAI 的技术团队成员，曾开发过受欢迎的 ChatGPT 检索插件，并且在教授 LLM （Large Language Model, 大语言模型）技术在产品中的应用方面做出了很大贡献。她还\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "推\n",
      "导细节的读者来说可能“不太友好”\n",
      "，本书旨在对西瓜书里比较难理解的公式加以解析，以及对部分公式补充\n",
      "具体的推导细节。\n",
      "”\n",
      "读到这里，大家可能会疑问为啥前面这段话加了引号，因为这只是我们最初的遐想，\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "1\n",
      "1.2\n",
      "基本术语\n",
      ". . . . . . . . . . . . . . . . . .\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      ". . . . . . . . . . . . . . . .\n",
      "23\n",
      "3.3.2\n",
      "梯度下降法. . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      " . . . . . . . . . . . . . . . .\n",
      "45\n",
      "5.5.1\n",
      "式(5.18) 的解释\n",
      ". . . . . . . . . . . . . . . . . . . . . . . \n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "62\n",
      "7.1.1\n",
      "式(7.5) 的推导. . . . . . . . . . . . . . . .\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      " . . . . . . . . . . . . . . . .\n",
      "83\n",
      "8.2.16 AdaBoost 的个人推导. . . . . . . . . . . . . . . . . . . . . .\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      ". . . . . . . . . . . . . . . .\n",
      "99\n",
      "9.2.5\n",
      "式(9.12) 的解释\n",
      ". . . . . . . . . . . . . . . . . . . . . . . .\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      " . . . . . . . . . . . . . . . .\n",
      "120\n",
      "10.6.2 式(10.20) 的解释. . . . . . . . . . . . . . . . . . . . . . \n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "136\n",
      "12.1.1 式(12.1) 的解释\n",
      ". . . . . . . . . . .\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      " . . . . . . . . . . . . . . . .\n",
      "149\n",
      "12.7.5 经验损失最小化. . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      " . . . . . . . . . . . . . . . .\n",
      "168\n",
      "14.2.5 式(14.8) 的解释\n",
      ". . . . . . . . . . . . . . . . . . . . . . \n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "2.7 式(15.13) 的解释. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "179\n",
      "15.2.8\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "复杂的算法理论，因此阅读本章时只需耐心梳理清楚所有概念和数学符号即可。此外，在\n",
      "阅读本章前建议先阅读西瓜书目录前页的《主要符号表》\n",
      "，它能解答在阅读“西瓜书”过程中产生的大部\n",
      "分对数学符号的疑惑。\n",
      "本\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "不同的训练集，训练得到的模型通常都不同。\n",
      "标记：上文提到机器学习的本质就是在学习样本在某个方面的表现是否存在潜在的规律，我们称该方\n",
      "面的信息为“标记”\n",
      "。例如在学习西瓜的好坏时，\n",
      "“好瓜”和“坏瓜”便\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "征就足以区分亚洲人和非洲人。\n",
      "而“算法则是让模型无限逼近上限”是指当数据相关的工作已准备充分时，接下来便可用各种可适用\n",
      "的算法从数据中学习其潜在的规律进而得到模型，不同的算法学习得到的模型效果自然有高\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "年; 学校数量: 3所; 房价: 9万/m2) 则结论便逆转为多项式回归算法优于一元线\n",
      "性回归算法。\n",
      "1.4.1\n",
      "式(1.1) 和式(1.2) 的解释\n",
      "X\n",
      "f\n",
      "Eote(La|X, f) =\n",
      "X\n",
      "f\n",
      "\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "习的相关数学符号，那么本章则进一步介绍机器学习的相关概念。具体来说，介绍内容正如本章名称\n",
      "“模型评估与选择”所述，讲述的是如何评估模型的优劣和选择最适合自己业务场景的模型。\n",
      "由于“模型评估与选择”是在\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "理，按照以上方法也可得到算法L 搭配方案b 在数据集D 上的最终效果Scoreb，最后通\n",
      "过比较Scorea 和Scoreb 之间的优劣来确定算法L 在数据集D 上效果最好的参数配置方案。\n",
      "对比不同算\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "2.9) 可算得查全率为1，但是此时TP + FP 为样本总数，根据式(2.8) 可算得查准率此时为正例在\n",
      "全体样本中的占比，显然在现实任务中正例的占比通常不为0，因此P-R 曲线在现实任务中通常不会\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "R 类别的影响，而“微”则考虑到了每个类别的样本数量，因为样本数量多\n",
      "的类相应的TP、FP、TN、FN 也会占比更多，所以在各类别样本数量极度不平衡的情况下，数量较多\n",
      "的类别会主导最终结果。\n",
      "式(2.\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "。其\n",
      "中绿色线段表示在分类阈值变动的过程中只新增了真正例，红色线段表示只新增了假正例，蓝色线段表示\n",
      "既新增了真正例也新增了假正例。根据AUC 值的定义可知，此时的AUC 值其实就是所有红色线段和蓝\n",
      "色\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      ") < f(x−)\n",
      "\u0001\n",
      "+\n",
      "1\n",
      "m−\n",
      "X\n",
      "x−∈D−\n",
      "I\n",
      "\u0000f(x+) = f(x−)\n",
      "\u0001\n",
      "#\n",
      "与式(2.20) 中的推导思路相同，不论是绿色线段还是蓝色线段，其与y 轴围成的图形面积都可以用\n",
      "梯形公\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      ") = 1\n",
      "m\n",
      "\n",
      "m+ ×\n",
      "1\n",
      "m+\n",
      "X\n",
      "xi∈D+\n",
      "I (f (xi ̸= yi)) × cost+−+ m−×\n",
      "1\n",
      "m−\n",
      "X\n",
      "xi∈D−\n",
      "I (f (xi ̸= yi)) × cost−+\n",
      "\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      " m × p × FNR × cost+−+ m × (1 −p) × FPR × cost−+\n",
      "+ m × p × TPR × cost++ + m × (1 −p) × TNR × cost−−\n",
      "\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "上的点又对应着具体的阈值）\n",
      "即为最佳阈值。\n",
      "原因是与该垂线最先相交的线段必然最\n",
      "靠下，因此其交点的纵坐标最小，而纵轴表示的便是归一化代价costnorm，所以此时归一化代价costnorm\n",
      "达到最小。\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "ˆ\n",
      "ϵ×m−1 恒大于0，\n",
      "(ˆ\n",
      "ϵ×m−ϵ×m)\n",
      "在0 ⩽ϵ < ˆ\n",
      "ϵ 时大于0，在ϵ = ˆ\n",
      "ϵ 时等于0，在ˆ\n",
      "ϵ ⩽ϵ < 1 时小于0，因此P(ˆ\n",
      "ϵ | ϵ) 是关于ϵ 开口向下的凹\n",
      "函\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "。具体如何取舍需要结合实际情况，一般的做法是使α 尽可能小，因此倾向于令C 取C + 1。\n",
      "下面考虑如何求解C。易证βφ(p0) 是关于C 的减函数，再结合上述关于C 的两个不等式易推得\n",
      "C = mi\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "\n",
      "f(x) + ¯\n",
      "f(x) −yD\n",
      "\u00012i\n",
      "2\n",
      "=ED\n",
      "h\u0000f(x; D) −¯\n",
      "f(x)\n",
      "\u00012i\n",
      "+ ED\n",
      "h\u0000 ¯\n",
      "f(x) −yD\n",
      "\u00012i\n",
      "+\n",
      "ED\n",
      "\u0002\n",
      "2\n",
      "\u0000f(x; D) −¯\n",
      "f(x)\n",
      "\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "D) −¯\n",
      "f(x)\n",
      "\u0001\n",
      "· ¯\n",
      "f(x)\n",
      "\u0003\n",
      "−ED\n",
      "\u0002\n",
      "2\n",
      "\u0000f(x; D) −¯\n",
      "f(x)\n",
      "\u0001\n",
      "· yD\n",
      "\u0003\n",
      "= 0 + 0\n",
      "= 0\n",
      "4 →5 ：同1 →2 一样，减一个y 再加一个y，属于简单\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "线性模型衍生而得，无论是曾经红极一时的支持向量机还是如今万众瞩目的神经网络，其中都\n",
      "有线性模型的影子。\n",
      "本章的线性回归和对数几率回归分别是回归和分类任务上常用的算法，因此属于重点内容，线性判别\n",
      "分析不\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "约束\n",
      "于”\n",
      "，即为约束条件。\n",
      "以上介绍的符号都是应用数学领域的一个分支——“最优化”中的内容，若想进一步了解可找一本最\n",
      "优化的教材（例如参考文献[1]）进行系统性地学习。\n",
      "3.2.3\n",
      "式(3.5) 的\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "\n",
      "m\n",
      "X\n",
      "i=1\n",
      "x2\n",
      "i =\n",
      "m\n",
      "X\n",
      "i=1\n",
      "yixi −\n",
      "m\n",
      "X\n",
      "i=1\n",
      "bxi\n",
      "由于令式(3.6) 等于0 可得b =\n",
      "1\n",
      "m\n",
      "Pm\n",
      "i=1(yi −wxi)，\n",
      "又因为\n",
      "1\n",
      "m\n",
      "Pm\n",
      "i=1 y\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "以类似得\n",
      "到\n",
      "(w∗, b∗) = arg min\n",
      "(w,b)\n",
      "m\n",
      "X\n",
      "i=1\n",
      "(f (xi) −yi)2\n",
      "= arg min\n",
      "(w,b)\n",
      "m\n",
      "X\n",
      "i=1\n",
      "(yi −f (xi))2\n",
      "= arg mi\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "数：含n 个自变量，值域为实数域R 的函数称为n 元实值函数，记为f(x)，其中x =\n",
      "(x1; x2; ...; xn) 为n 维向量。\n",
      "“西瓜书”和本书中的多元函数未加特殊说明均为实值函数。\n",
      "凸集\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "(3.11)。下面按照此思路进行推导。\n",
      "由于式(3.10) 已推导出E ˆ\n",
      "w 关于ˆ\n",
      "w 的一阶导数，接着基于此进一步推导出二阶导数，即Hessian 矩\n",
      "阵。推导过程如下：\n",
      "∇2E ˆ\n",
      "w =\n",
      "∂\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "m\n",
      "i=1(βTˆ\n",
      "xi −ln(1 + eβT ˆ\n",
      "xi)),\n",
      "yi = 1\n",
      "两式综合可得\n",
      "ℓ(β) =\n",
      "m\n",
      "X\n",
      "i=1\n",
      "\u0010\n",
      "yiβTˆ\n",
      "xi −ln(1 + eβT ˆ\n",
      "xi)\n",
      "\u0011\n",
      "由于此式仍为极\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      ") 取到最小值的x∗。\n",
      "显然，此算法要想行得通就必须解决在找到第t 个点xt 时，能进一步找到第t + 1 个点xt+1，且保\n",
      "证f(xt+1) < f(xt)。梯度下降法利用“梯度指向的方向是函数值\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "∂(x −xt)\n",
      "T ∇2f (xt) (x −xt)\n",
      "∂x\n",
      "= 0 + ∇f\n",
      "\u0000xt\u0001\n",
      "+ 1\n",
      "2\n",
      "\u0010\n",
      "∇2f\n",
      "\u0000xt\u0001\n",
      "+ ∇2f\n",
      "\u0000xt\u0001T\u0011 \u0000x −xt\u0001\n",
      "假设函数f(x) 在xt 处二阶可\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "xi(yi −ˆ\n",
      "yi)\n",
      "=\n",
      "m\n",
      "X\n",
      "i=1\n",
      "ˆ\n",
      "xi(ˆ\n",
      "yi −yi)\n",
      "= XT(ˆ\n",
      "y −y)\n",
      "其中ˆ\n",
      "y = (ˆ\n",
      "y1; ˆ\n",
      "y2; ...; ˆ\n",
      "ym), y = (y1; y2; ...\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "的投影y 很相近，而异类样本在w 上的投影y 很疏远。然后对于新的测试样本\n",
      "xi，将其代入模型得到它在w 上的投影yi，然后判别这个投影yi 与哪一类投影更近，则将其判为该类。\n",
      "最后，线性判别分析也是\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "m\n",
      "X\n",
      "i=1\n",
      "(xi −µ)(xi −µ)T −\n",
      "N\n",
      "X\n",
      "i=1\n",
      "X\n",
      "x∈Xi\n",
      "(x −µi)(x −µi)T\n",
      "=\n",
      "N\n",
      "X\n",
      "i=1\n",
      " X\n",
      "x∈Xi\n",
      "\u0000(x −µ)(x −µ)T −(x −µi)(x\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "于如下优化问题\n",
      "min\n",
      "w\n",
      "−tr(WTSbW)\n",
      "s.t.\n",
      "tr(WTSwW) = 1\n",
      "根据拉格朗日乘子法，可定义上述优化问题的拉格朗日函数\n",
      "L(W, λ) = −tr(WTSbW) + λ(tr(W\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "1 个最大的λi 即\n",
      "可。根据Sbwi = λiSwwi 可知，λi 对应的便是广义特征值，wi 是λi 所对应的特征向量。\n",
      "（广义特征值的定义和常用求解方法可查阅[3]）\n",
      "对于N 分类问题，一定要求\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "具也仅是为了让该算法在计算上可行，同时“西瓜书”在本章列举了大量例子，因此本章的\n",
      "算法会更为通俗易懂。\n",
      "4.1\n",
      "基本流程\n",
      "作为本章的开篇，首先要明白决策树在做什么。正如“西瓜书”中图4.1 所示的决策\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "总数，pk 表示第k 类样本所占的比例，有0 ⩽pk ⩽1, Pn\n",
      "k=1 pk = 1。若令\n",
      "|Y| = n, pk = xk，那么信息熵Ent(D) 就可以看作一个n 元实值函数，即\n",
      "Ent(D)\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "显然0 ⩽1\n",
      "n ⩽1，所以x1 = x2 = · · · = xn = 1\n",
      "n 是满足所有约束的\n",
      "最优解，即当前最小化问题的最小值点，同时也是f(x1, · · · , xn) 的最大值点。将x1 \n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "后另\n",
      "一个随机变量的不确定性减少的程度。\n",
      "下面给出互信息的定义，在此之前，还需要先解释一下什么是“条件熵”\n",
      "。条件熵表示的是在已知一\n",
      "个随机变量的条件下，另一个随机变量的不确定性。具体地，假设有随机变\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "pk′\n",
      "= (p1p1 + p2p2 + p3p3) + (p1p2 + p1p3 + p2p1 + p2p3 + p3p1 + p3p2)\n",
      "= (p1p1 + p1p2 + p1p3) + (p2p\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "Gini_index(D, 敲声= 清脆) = 0.439\n",
      "Gini_index(D, 纹理= 清晰) = 0.286\n",
      "Gini_index(D, 纹理= 稍稀) = 0.437\n",
      "Gini_index\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "复上述步骤，直至满足停止条件. 这样就生成了一棵CART 回归树，假\n",
      "设最终将特征空间划分为M 个子空间R1, R2, · · · , RM，那么CART 回归树的模型式可以表示为\n",
      "f(x) =\n",
      "M\n",
      "\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "45\n",
      "2\n",
      ", 0.245 + 0.343\n",
      "2\n",
      ", 0.343 + 0.360\n",
      "2\n",
      ", 0.360 + 0.403\n",
      "2\n",
      ", 0.403 + 0.437\n",
      "2\n",
      ", 0.437 + 0.481\n",
      "2\n",
      ",\n",
      "0.4\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "0.6\n",
      "0.4\n",
      "0.2\n",
      "0.2\n",
      "0.4\n",
      "0.6\n",
      "0.8\n",
      "0\n",
      "(a) 第一次划分\n",
      "含糖率\n",
      "密度\n",
      "0.6\n",
      "0.4\n",
      "0.2\n",
      "0.2\n",
      "0.4\n",
      "0.6\n",
      "0.8\n",
      "0\n",
      "(b) 第二次划分\n",
      "含糖率\n",
      "密度\n",
      "0.6\n",
      "0.\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "决策树等算法一样均属于机器学习算法，也是被发明用来完成分类和回归等任务。不过由于神\n",
      "经网络类算法在如今超强算力的加持下效果表现极其出色，且从理论角度来说神经网络层堆叠得越深其效\n",
      "果越好，因此也单独称用\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "ˆ\n",
      "y = 1，样本真实标记为y = 0；反之，当wTx −θ < 0 时，模型输出值为ˆ\n",
      "y = 0，样本真实标记\n",
      "为y = 1。综合两种情形可知，以下公式恒成立：\n",
      "(ˆ\n",
      "y −y)\n",
      "\u0000wTx −θ\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "现“异或”计算的过程如下：\n",
      "(x1, x2) →h1 = ε(x1 −x2 −0.5), h2 = ε(x2 −x1 −0.5) →y = ε(h1 + h2 −0.5)\n",
      "以(0, 1) 为例，\n",
      "首先\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "bh\n",
      "∂αh\n",
      "·\n",
      "∂αh\n",
      "∂vih\n",
      "=\n",
      "l\n",
      "X\n",
      "j=1\n",
      "∂Ek\n",
      "∂ˆ\n",
      "yk\n",
      "j\n",
      "·\n",
      "∂ˆ\n",
      "yk\n",
      "j\n",
      "∂βj\n",
      "·\n",
      "∂βj\n",
      "∂bh\n",
      "·\n",
      "∂bh\n",
      "∂αh\n",
      "· xi\n",
      "=\n",
      "l\n",
      "X\n",
      "j=1\n",
      "∂Ek\n",
      "∂ˆ\n",
      "yk\n",
      "j\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "部极小和全局最小的概念，其余概念如模拟退火、遗传算法、启发式等，则\n",
      "需要查阅专业资料系统化学习。\n",
      "5.5\n",
      "其他常见神经网络\n",
      "本节所提到的神经网络其实如今已不太常见，更为常见的神经网络是下一节深度学习里\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "如何理解深度学习。因此，本书也顺着“西瓜书”的思路对深度学习相关概念作进一步说明，\n",
      "对深度学习的经典神经网络感兴趣的读者可查阅其他相关书籍进行系统性学习。\n",
      "5.6.1\n",
      "什么是深度学习\n",
      "深度学习就是很深\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "关学者在持续研究。\n",
      "6.1\n",
      "间隔与支持向量\n",
      "6.1.1\n",
      "图6.1 的解释\n",
      "回顾第5 章5.2 节的感知机模型可知，图6.1 中的黑色直线均可作为感知机模型的解，因为感知机模\n",
      "型求解的是能将正负样本完全\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "以将其划分到负空间）\n",
      "，yi = −1 的负样本被划分到负空间，以下不等式成立\n",
      "(\n",
      "wTxi + b ⩾0,\n",
      "yi = +1\n",
      "wTxi + b ⩽0,\n",
      "yi = −1\n",
      "对于第二个条件，首先设离超平面最\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      " 1, 2, ..., m\n",
      "hj(x) = 0,\n",
      "j = 1, 2, ..., n\n",
      "若目标函数f(x) 是凸函数，不等式约束gi(x) 是凸函数，等式约束hj(x) 是仿射函数，则称该优化问题\n",
      "为凸优\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "拉格朗日对偶函数Γ(µ, λ)（简\n",
      "称对偶函数）定义为L(x, µ, λ) 关于x 的下确界，即\n",
      "Γ(µ, λ) = inf\n",
      "x∈D L(x, µ, λ) = inf\n",
      "x∈D\n",
      " \n",
      "f(x) +\n",
      "m\n",
      "X\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "最优解，且此时强对偶性成立。下面给出具体的推导过程。\n",
      "设x∗, µ∗, λ∗是任意满足KKT 条件的点，即\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "∇xL(x∗, µ∗, \n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      ", hj(x∗) = 0\n",
      "便凑齐了KKT 条件。\n",
      "6.2.5\n",
      "式(6.9) 和式(6.10) 的推导\n",
      "L(w, b, α) = 1\n",
      "2∥w∥2 +\n",
      "m\n",
      "X\n",
      "i=1\n",
      "αi(1 −yi(wTxi + b)\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "m 对应训练样本个数，通常m ≪d，所以求解式(6.11) 更高效，反之求解式(6.6) 更高效；\n",
      "(2) 式(6.11) 中有样本内积x\n",
      "Txj\n",
      "i\n",
      "这一项，后续可以很自然地引入核函数，进而使得支持\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      ".35) 的对偶问题，有\n",
      "1\n",
      "2 ∥w∥2 + C\n",
      "m\n",
      "X\n",
      "i=1\n",
      "ξi +\n",
      "m\n",
      "X\n",
      "i=1\n",
      "αi\n",
      "\u00001 −ξi −yi\n",
      "\u0000wTxi + b\n",
      "\u0001\u0001\n",
      "−\n",
      "m\n",
      "X\n",
      "i=1\n",
      "µiξi\n",
      "=1\n",
      "2 ∥w∥2 +\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      " +1\n",
      "Pm\n",
      "i=1 ln\n",
      "\u0010\n",
      "1 + ewTxi+b\u0011\n",
      ",\n",
      "yi = −1\n",
      "=\n",
      "m\n",
      "X\n",
      "i=1\n",
      "ln\n",
      "\u0010\n",
      "1 + e−yi(wTxi+b)\u0011\n",
      "此时上式的求和项正是式(6.33) 所表述的对率损失。\n",
      "\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "+ ˆ\n",
      "ξi\n",
      "\u0011\n",
      "s.t.\n",
      "−ϵ −ˆ\n",
      "ξi ⩽f (xi) −yi ⩽ϵ + ξi\n",
      "ξi ⩾0, ˆ\n",
      "ξi ⩾0, i = 1, 2, . . . , m\n",
      "6.5.3\n",
      "式(6.52) 的推导\n",
      "将式(\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "x) =\n",
      "m\n",
      "X\n",
      "i=1\n",
      "αiκ (x, xi)\n",
      "又因为直线方程的固定形式为\n",
      "h(x) = wTϕ(x)\n",
      "所以\n",
      "wTϕ(x) =\n",
      "m\n",
      "X\n",
      "i=1\n",
      "αiκ (x, xi)\n",
      "将κ (x, xi) = ϕ(\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "\n",
      "κ (x2, x1) + κ (x2, x3)\n",
      "κ (x3, x1) + κ (x3, x3)\n",
      "κ (x4, x1) + κ (x4, x3)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "∈R4×1\n",
      "ˆ\n",
      "µ1 = 1\n",
      "\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "ϕ(x) =\n",
      "\u0000ϕ(xi)Tϕ(x)\n",
      "\u0001T =\n",
      "ϕ(x)Tϕ(xi) = κ (xi, x)T，将其代入上式可得\n",
      "wTSϕ\n",
      "b w =\n",
      " \n",
      "1\n",
      "m1\n",
      "m\n",
      "X\n",
      "i=1\n",
      "X\n",
      "x∈X1\n",
      "αiκ (xi, x\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "=1\n",
      "αiϕ (xi)\n",
      "=\n",
      "m\n",
      "X\n",
      "i=1\n",
      "αiϕ (xi)T ·\n",
      " X\n",
      "x∈D\n",
      "ϕ(x)ϕ(x)T −m0µϕ\n",
      "0\n",
      "\u0010\n",
      "µϕ\n",
      "0\n",
      "\u0011T\n",
      "−m1µϕ\n",
      "1\n",
      "\u0010\n",
      "µϕ\n",
      "1\n",
      "\u0011T!\n",
      "·\n",
      "m\n",
      "X\n",
      "i=1\n",
      "αi\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "min\n",
      "w,b\n",
      "1\n",
      "m\n",
      "m\n",
      "X\n",
      "i=1\n",
      "log\n",
      "\u0010\n",
      "1 + e−yi(wTzi+b)\u0011\n",
      "+ λ\n",
      "2m∥w∥2\n",
      "注意，\n",
      "以上两式中的w 维度是不同的，\n",
      "其分别与xi 和zi 的维度一致。\n",
      "根据表示定理，\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "的理论性会更强。朴素贝叶斯算法常用于文本分类，例如用于广告邮件检测，贝叶斯网和EM 算\n",
      "法均属于概率图模型的范畴，因此可合并至第14 章一起学习。\n",
      "7.1\n",
      "贝叶斯决策论\n",
      "7.1.1\n",
      "式(7.5) 的推\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "得\n",
      "(ˆ\n",
      "µc, ˆ\n",
      "Σc) = arg min\n",
      "(µc,Σc)\n",
      "−\n",
      "X\n",
      "x∈Dc\n",
      "log\n",
      "\"\n",
      "1\n",
      "p\n",
      "(2π)d|Σc|\n",
      "exp\n",
      "\u0012\n",
      "−1\n",
      "2(x −µc)TΣ−1\n",
      "c (x −µc)\n",
      "\u0013#\n",
      "= a\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "型。\n",
      "根据正定二次型的性质可知，\n",
      "此时上式最后一项的取值仅与µc −¯\n",
      "x 相关，\n",
      "并有当且仅当µc −¯\n",
      "x = 0\n",
      "时，上式最后一项取最小值0，此时可以解得\n",
      "ˆ\n",
      "µc = ¯\n",
      "x = 1\n",
      "n\n",
      "n\n",
      "\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "um\n",
      "A Posteriori Estimation，简称MAP）\n",
      "、后验中位数估计和后验期望值估计这3 种参数估计方法，下面给\n",
      "出这3 种方法的具体定义。\n",
      "设总体的概率质量函数（若总体的分布为连续型\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "θ2, ..., θk) ∈Rk 的Categorical\n",
      "分布，其概率质量函数为\n",
      "P(C = ci) = P(ci) = θi\n",
      "其中P(ci) = θi 就是式(7.9) 所要求解的ˆ\n",
      "P(c)，下\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "t 分布的定义可知\n",
      "P(θ; α + y) =\n",
      "Γ\n",
      "\u0010Pk\n",
      "i=1(αi + yi)\n",
      "\u0011\n",
      "Qk\n",
      "i=1 Γ(αi + yi)\n",
      "k\n",
      "Y\n",
      "i=1\n",
      "θαi+yi−1\n",
      "i\n",
      "X\n",
      "θ\n",
      "P(θ; α + y) =\n",
      "\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "i, xj|cn) log\n",
      "P(xi, xj|cn)\n",
      "P(xi|cn)P(xj|cn)\n",
      "其中i, j = 1, 2, ..., d 且i ̸= j，N 为类别个数。该式共可得到d(d−1)\n",
      "2\n",
      "个I(\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      " 的条件下x3, x4 独立\n",
      "P(x3, x4|x1) = P(x1, x3, x4)\n",
      "P(x1)\n",
      "= P(x1)P(x3|x1)P(x4|x1)\n",
      "P(x1)\n",
      "= P(x3|x1)P(x4|x1)\n",
      "顺\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "较难求解，而EM 算法则给出了一种迭代的方法来完成对LL(θ) 的极大化。\n",
      "下面给出两种推导方法，\n",
      "一个是出自李航老师的\n",
      "《统计学习方法》\n",
      "[2]，\n",
      "一个是出自吴恩达老师的CS229，\n",
      "两种推导方式虽\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "，\n",
      "于是问题就转化为了求解能使得B(θ, θ(t))\n",
      "达到极大的θ(t+1)，即\n",
      "θ(t+1) = arg max\n",
      "θ\n",
      "B(θ, θ(t))\n",
      "= arg max\n",
      "θ\n",
      "\n",
      "LL(θ(t)) +\n",
      "X\n",
      "Z\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      " 为LL(θ) 的下界函数，那么这个下界函数所能构成\n",
      "的最优下界是多少？即B(θ) 的最大值是多少？显然，B(θ) 是LL(θ) 的下界函数，反过来LL(θ) 是其上\n",
      "界函数，所以如果能使得B(θ) \n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "1\n",
      "X\n",
      "zi\n",
      "p(zi|xi; θ(t+1)) ln\n",
      "p(xi, zi; θ(t+1))\n",
      "p(zi|xi; θ(t+1))\n",
      "10\n",
      "⩾\n",
      "m\n",
      "X\n",
      "i=1\n",
      "X\n",
      "zi\n",
      "p(zi|xi; θ(t)) ln\n",
      "p(\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "\u0015\n",
      "可作如下恒等变形：\n",
      "X\n",
      "z1,z2,...,zm\n",
      "\" m\n",
      "Y\n",
      "i=1\n",
      "P(zi|xi, θ(t)) · ln P(x1, z1|θ)\n",
      "#\n",
      "=\n",
      "X\n",
      "z1,z2,...,zm\n",
      "\" m\n",
      "Y\n",
      "i=2\n",
      "P(\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "li.com/video/BV1Mh411e7VU\n",
      "←_←\n",
      "\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "鲁棒、效果\n",
      "更好的学习器。在“西瓜书”作者周志华教授的谷歌学术主页的top 引用文章（图8-1）中，很大一部分都\n",
      "和集成学习有关。\n",
      "图8-1 周志华教授谷歌学术top10 引用文章(截止到2023-0\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "法有两种，\n",
      "除\n",
      "了本节的多数投票(majority voting)，\n",
      "还有概率投票(probability voting)，\n",
      "这两点在8.4 节中均会提及，\n",
      "即\n",
      "硬投票和软投票。\n",
      "8.1.1\n",
      "式(8.\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "个体学习器间存在强依赖关系、必须串行生成的序列化方法，以及个体学习器间不存在强依赖关系、可同\n",
      "时生成的并行化方法。\n",
      "本节Boosting 为前者的代表，Adaboost 又是Boosting 族算法的\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "\n",
      "\u0002\n",
      "e−f(x)H(x)\u0003\n",
      "=\n",
      "X\n",
      "x∈D\n",
      "D(x)e−f(x)H(x)\n",
      "=\n",
      "|D|\n",
      "X\n",
      "i=1\n",
      "D (xi)\n",
      "\u0000e−H(xi)I (f (xi) = 1) + eH(xi)I (f (xi) = \n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      " = y|x) 表示使\n",
      "得函数P(f(x) = y|x) 取得最大值的y 的值，展开刚好是第二行的式子。\n",
      "这里解释一下贝叶斯错误率的概念。这来源于“西瓜书”P148 的式(7.6) 表示的贝叶斯最优分\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "8.19) 的推导结果。\n",
      "AdaBoost 第t 轮迭代应该求解如下优化问题从而得到αt 和ht(x) :\n",
      "(αt, ht(x)) = arg min\n",
      "α,h\n",
      "ℓexp (Ht−1 + αh | D)\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "rg min\n",
      "h\n",
      "Ex∼D\n",
      "\u0014\n",
      "e−f(x)Ht−1(x)\n",
      "\u0012\n",
      "1 −f(x)h(x) + 1\n",
      "2\n",
      "\u0013\u0015\n",
      "2\n",
      "= arg max\n",
      "h\n",
      "Ex∼D\n",
      "\u0002\n",
      "e−f(x)Ht−1(x)f(x)h(x)\n",
      "\u0003\n",
      "3\n",
      "\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      ")h(x)\n",
      "\u0015\n",
      "=\n",
      "|D|\n",
      "X\n",
      "i=1\n",
      "D (xi)\n",
      "e−f(xi)Ht−1(xi)\n",
      "Ex∼D [e−f(x)Ht−1(x)] f(xi)h(xi)\n",
      "=\n",
      "|D|\n",
      "X\n",
      "i=1\n",
      "Dt (xi) f (xi\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "\n",
      "AdaBoost 的个人推导\n",
      "西瓜书中对AdaBoost 的推导和原论文[1] 上有些地方有差异，综合原论文和一些参考资料，这里给\n",
      "出一版更易于理解的推导，亦可参见我们的视频教程。\n",
      "AdaBoost\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "−1 + αh | D) =\n",
      "|D|\n",
      "X\n",
      "i=1\n",
      "D (xi) e−f(xi)Ht−1(xi) \u0000e−α +\n",
      "\u0000eα −e−α\u0001\n",
      "I (f (xi) ̸= h (xi))\n",
      "\u0001\n",
      "=\n",
      "|D|\n",
      "X\n",
      "i=1\n",
      "\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "能\n",
      "是由于过拟合产生的结果, 例如不前枝决策树, 如果一直分下去, 一般情况下总能得到在训练集上分类误差\n",
      "很小甚至为0 的分类器, 但这并没有什么意义。所以一般在AdaBoost 中使用弱分类器, 如\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "t−1\n",
      "Zt−1\n",
      "e−f(x)αt−1ht−1(x)\n",
      "其中根据式(8.11), 第t −1 轮的权重\n",
      "αt−1 = 1\n",
      "2 ln 1 −ϵt−1\n",
      "ϵt−1\n",
      "= ln\n",
      "s\n",
      "1 −ϵt−1\n",
      "ϵt−1\n",
      "代入\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "t (xi) 选择样本xi 即可。\n",
      "注意, 这里总的损失中出现了样本个数m 。这是因为在定义损失时末求均值, 若对式(6.29) 的第二\n",
      "项和式(3.27) 乘以\n",
      "1\n",
      "m 则可以将m 抵消掉。然而常数\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "voting)，\n",
      "本页左侧注释也提到多数投\n",
      "票法的英文术语使用不太一致，有文献称为majority voting。本人看到有些文献中，硬投票使用majority\n",
      "voting（多数投票）\n",
      "，软投票使用\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "书”图8.9 下方的一段话有详细的讨论，不再赘述。\n",
      "8.5\n",
      "多样性\n",
      "8.5.1\n",
      "式(8.27) 的解释\n",
      "A (hi|x) = (hi(x) −H(x))2\n",
      "该式表示个体学习器结果与预测结果的差值的平方\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "(f(x) −H(x))2\n",
      "=\n",
      "T\n",
      "X\n",
      "i=1\n",
      "wihi(x)2 −H(x)2\n",
      "所以\n",
      "¯\n",
      "A(h|x) =\n",
      "T\n",
      "X\n",
      "i=1\n",
      "wiE (hi|x) −E(H|x)\n",
      "8.5.6\n",
      "式(8.32) 的解释\n",
      "T\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "p1 ⩾p2, 即κ ⩾0, 但偶尔也有p1 < p2 的情况,\n",
      "此时κ < 0 。有关p1, p2 的意义参见式(8.41) 和式(8.42) 的解释。\n",
      "8.5.12\n",
      "式(8.41) 的解释\n",
      "分子a\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      " (xk) =\n",
      "∇f(x)\n",
      "∇x\n",
      "\f",
      "\n",
      "\f",
      "\n",
      "\f",
      "\n",
      "x=xk ̸= 0 。将f(x) 在xk 处进行一阶Taylor 展开\n",
      "f(x) ≈f (xk) + ∇f (xk)T (x −xk)\n",
      "记x −xk = \n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      " ∆x) = 0 。例2: 试求f(x) = ∥x∥2\n",
      "2 = xTx 在xk = [x1\n",
      "k, x2\n",
      "k]\n",
      "T = [3, 4]T 处\n",
      "的梯度方向dk 和步长αk 。解: 对f(x) 在xk = [\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      " Ht−1(x) 处\n",
      "泰勒展开, 得\n",
      "g(z) ≈g (z0) + g′ (z0) (z −z0)\n",
      "= g (z0) −f(x)e−f(x)z0 (z −z0)\n",
      "= e−f(x)Ht−1(x) −e−\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "失函数, 也不局限于二分类问题, 则可以将式\n",
      "(8.5) 写为更一般化的形式\n",
      "ℓ(Ht | D) = Ex∼D [err (Ht(x), f(x))]\n",
      "= Ex∼D [err (Ht−1(x) + α\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "格限制∥d∥2 = 1, 长度可以由步长α 调节(例如前面梯度下降方解释中的例1 , 若直接取\n",
      "dk = −f ′ (xk) = −4, 则可得αk = 0.5, 仍有∆x = αkdk = −2),\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "绍的聚类(clus-\n",
      "tering) 和下一章介绍的降维属于无监督学习(unsupervised learning)。\n",
      "9.1\n",
      "聚类任务\n",
      "单词“cluster”既是动词也是名词，作为名词时翻译为“簇”\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "类结果的同一个类的样本对，即A = SS S SD，集合B 中存放着两个样本都同属于参考模型\n",
      "的同一个类的样本对，即B = SS S DS，那么根据Jaccard 系数的定义有：\n",
      "JC = |A T \n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "上“蜷缩”和“稍蜷”\n",
      "两个离散值之间的距离。\n",
      "此时, u 为“根蒂”, a 为属性根蒂上取值为“蜷缩”, b 为属性根蒂上取值为“稍蜷”, 根据边注, 此\n",
      "时样本类别已知(好瓜/坏瓜), 因此k = \n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      " Σi)\n",
      "(即将式(9.28) 中的µ, Σ 替换为µi, Σi) 进行采样生成样本x 。两个步骤的区别在于第1 步选择高斯混\n",
      "合成分时是从k 个之中选其一(相当于概率密度函数是离散的), 而第2 步\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      ", 以致于计算机无法表达这么小的数, 产生下溢), 所以常用对数似然替代, 即式(9.32)。\n",
      "9.4.6\n",
      "式(9.33) 的推导\n",
      "根据公式(9.28) 可知：\n",
      "p (xj|µi, Σi) =\n",
      "1\n",
      "(\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "是因为µi 对于求和变量j 来说是常量, 因此可以提到求和号外面; 因此\n",
      "µi =\n",
      "Pm\n",
      "j=1 γjixj\n",
      "Pm\n",
      "j=1 γji\n",
      "9.4.8\n",
      "式(9.35) 的推导\n",
      "根据公式(9.28) 可知：\n",
      "p\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "Pk\n",
      "l=1 αl · p(xj|µl, Σl)\n",
      "·\n",
      "\n",
      "−\n",
      "1\n",
      "2Σ−1\n",
      "i\n",
      "+\n",
      "1\n",
      "2Σ−1\n",
      "i (xj −µi)(xj −µi)T Σ−1\n",
      "i\n",
      "\n",
      "\n",
      "又由公式(9.30) 可知\n",
      "αi · p\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "−1)\n",
      "∂αi\n",
      "= 1\n",
      "综合两项求导结果, 并令导数等于零即得式(9.37)。\n",
      "9.4.11\n",
      "式(9.38) 的推导\n",
      "注意, 在“西瓜书”第14 次印刷中式(9.38) 上方的一行话进行了勘误: “两\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "行计\n",
      "算γji 再次使用。\n",
      "整体来说, 第2 ~12 行就是一个EM 算法的具体使用例子, 学习完7.6 节EM 算法可能根本无法理解\n",
      "其思想。此例中有两组变量, 分别是γji 和(αi, µi, Σ\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "并存于集合Ω之中; 第\n",
      "4 行的if 判断语句即在判别xj 是否为核心对象。\n",
      "在第10 ∼24 行中, 以任一核心对象为出发点(由第12 行实现), 找出其密度可达的样本生成聚类簇\n",
      "(由第14 ∼21\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "如下。\n",
      "10.1.1\n",
      "符号约定\n",
      "向量元素之间分号“;”表示列元素分隔符, 如α = (a1; a2; . . . ; ai; . . . ; am) 表示m × 1 的列向量; 而逗\n",
      "号“,”表示行元\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "2\n",
      "· · ·\n",
      "a1j\n",
      "· · ·\n",
      "a1n\n",
      "a21\n",
      "a22\n",
      "· · ·\n",
      "a2j\n",
      "· · ·\n",
      "a2n\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "...\n",
      ".\n",
      ".\n",
      ".\n",
      "...\n",
      ".\n",
      ".\n",
      ".\n",
      "ai1\n",
      "ai2\n",
      "· · ·\n",
      "aij\n",
      "\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "cii =\n",
      "m\n",
      "X\n",
      "i=1\n",
      " n\n",
      "X\n",
      "j=1\n",
      "|aij|2\n",
      "!\n",
      "=\n",
      "m\n",
      "X\n",
      "i=1\n",
      "n\n",
      "X\n",
      "j=1\n",
      "|aij|2 = ∥A∥2\n",
      "F\n",
      "有关方阵的特征值之和等于对角线元素之和, 可以参见线性代数教材。\n",
      "1\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "度这一维（竖着的坐标轴）后，\n",
      "红色线变成直线，而直线更容易学习。\n",
      "10.4.2\n",
      "式(10.3) 的推导\n",
      "已知Z = {z1, z2, . . . , zi, . . . , zm} ∈Rd′×m, 其\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "\n",
      "m\n",
      "X\n",
      "i=1\n",
      "\u0010\n",
      "∥zi∥2 + ∥zj∥2 −2z⊤\n",
      "i zj\n",
      "\u0011\n",
      "=\n",
      "m\n",
      "X\n",
      "i=1\n",
      "∥zi∥2 +\n",
      "m\n",
      "X\n",
      "i=1\n",
      "∥zj∥2 −2\n",
      "m\n",
      "X\n",
      "i=1\n",
      "z⊤\n",
      "i zj\n",
      "根据定义：\n",
      "m\n",
      "X\n",
      "i=\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "j)\n",
      "由式(10.6) 和(10.9) 可得\n",
      "tr(B) =\n",
      "1\n",
      "2m\n",
      "m\n",
      "X\n",
      "i=1\n",
      "m\n",
      "X\n",
      "j=1\n",
      "dist2\n",
      "ij\n",
      "= m\n",
      "2 dist2\n",
      "·\n",
      "由式(10.4) 和(10.8) 可得\n",
      "bjj =\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "向量矩阵, ￿∈Rm×m 为特征值构成的对角矩阵, 接下来分类讨论：\n",
      "(1) 当d > m 时, 即样本属性比样本个数还要多此时, 样本集合X ∈Rd×m 的d 维属性一定是线性相\n",
      "关的(即有品几余)\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "\n",
      "∥Wzi −xi∥2\n",
      "2\n",
      "1\n",
      "=\n",
      "m\n",
      "X\n",
      "i=1\n",
      "\r\n",
      "\r",
      "WW⊤xi −xi\n",
      "\r\n",
      "\r",
      "2\n",
      "2\n",
      "2\n",
      "=\n",
      "m\n",
      "X\n",
      "i=1\n",
      "\u0000WW⊤xi −xi\n",
      "\u0001⊤\u0000WW⊤xi −xi\n",
      "\u0001\n",
      "3\n",
      "=\n",
      "m\n",
      "X\n",
      "i=1\n",
      "\u0000x⊤\n",
      "\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "id\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "h\n",
      "xi1\n",
      "xi2\n",
      "· · ·\n",
      "xid\n",
      "i\n",
      "=\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "xi1xi1\n",
      "xi1xi2\n",
      "· · ·\n",
      "xi1xid\n",
      "xi2xi1\n",
      "xi2xi2\n",
      "· · \n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "1\n",
      "n\n",
      "n\n",
      "X\n",
      "i=1\n",
      "(xi −M)2\n",
      "方差衡量了该组数据偏离均值的程度，样本越分散, 其方差越大。\n",
      "再说什么是协方差，若还有包含n 个样本的另一组数据X′ = {x′\n",
      "1, x′\n",
      "2, . . .\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      " W⊤X, 而常系数\n",
      "1\n",
      "m 在最大化时并不发生影响, 求矩阵对角线元素之和即为矩阵的迹, 综上即得式\n",
      "(10.16)。\n",
      "另外, 中心化后X 的各行均值为零, 变换后Z = W⊤X 的各行均值仍为零,\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "定义式，其中λi, wi 分别表示矩阵XXT 的特征值和单位特征\n",
      "向量。由于以上是仅考虑约束wT\n",
      "i wi = 1 所求得的结果，而wi 还需满足约束wT\n",
      "i wj = 0(i ̸= j)。观察\n",
      "XX\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      " = ZZ⊤, 其中Z 的每一列为一个样本, 设\n",
      "高维空间的维度为h, 则Z ∈Rh×m, 其中m 为数据集样本数量。\n",
      "其次, 式(10.19) 中的W 为从高维空间降至低维(维度为d ) 后的正交基\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "，所以问题转化为了求解满足下式的αj：\n",
      "ZTZαj = λjαj\n",
      "令ZTZ = K，那么上式可化为\n",
      "Kαj = λjαj\n",
      "此式即为公式(10.24)，其中矩阵K 的第i 行第j 列的元素(K)ij =\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "如下恒等变形\n",
      "m\n",
      "X\n",
      "i=1\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r",
      "xi −\n",
      "X\n",
      "j∈Qi\n",
      "wijxj\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "2\n",
      "2\n",
      "=\n",
      "m\n",
      "X\n",
      "i=1\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "X\n",
      "j∈Qi\n",
      "wijxi −\n",
      "X\n",
      "j∈Qi\n",
      "wi\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      ")−1I\n",
      "若令矩阵(XT\n",
      "i Xi)−1 第j 行第k 列的元素为C−1\n",
      "jk ，则\n",
      "wij = wiqj\n",
      "i =\n",
      "P\n",
      "k∈Qi\n",
      "C−1\n",
      "jk\n",
      "P\n",
      "l,s∈Qi\n",
      "C−1\n",
      "ls\n",
      "此即为公式(10.28)\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "\n",
      "2 = ∥V∥2\n",
      "F\n",
      "= tr\n",
      "\u0000VV⊤\u0001\n",
      "= tr\n",
      "\u0010\u0000Z(I −W)⊤\u0001 \u0000Z(I −W)⊤\u0001⊤\u0011\n",
      "= tr\n",
      "\u0000Z(I −W)⊤(I −W)Z⊤\u0001\n",
      "= tr\n",
      "\u0000ZMZZ⊤\u0001\n",
      "接下来求解式(10.\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "22 + . . . + ududmdd\n",
      "而式(10.32) 的结果则要更进一步, 去除对角线部分中的权重mii(1 ⩽i ⩽d) 部分, 即\n",
      "u1u1 + u2u2 + . . . + udud\n",
      "对\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "概率之和最大, 即\n",
      "maxM\n",
      "Pm\n",
      "i=1 pxi\n",
      "n∗, 但优化问题习惯是最小化, 所以改为minM −Pm\n",
      "i=1 pxi\n",
      "n∗即可, 而式(10.38) 目标函数中的\n",
      "常数1 并不影响优化结果,\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "维有相似的动机。特征选择与降维的\n",
      "区别在于特征选择是从所有特征中简单地选出相关特征, 选择出来的特征就是原来的特征; 降维则对原来\n",
      "的特征进行了映射变换, 降维后的特征均不再是原来的特征。\n",
      "本节涉及“\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      " 行d = |A| 中的|A| 表示特征集A 的包含的特征个数; 第9 行E′ < E 表示学习器L 在特征子\n",
      "集A′ 上的误差比当前特征子集A 上的误差更小, (E′ = E) ∨(d′ < d) \n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "数的变化不能太快。\n",
      "将式(11.9)\n",
      "变形则更为直观(注: 式中应该是2 范数, 而非2 范数平方):\n",
      "∥∇f (x′) −∇f(x)∥2\n",
      "∥x′ −x∥2\n",
      "⩽L,\n",
      "(∀x, x′)\n",
      "进一步地, 若x\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      ":\n",
      "ˆ\n",
      "f\n",
      "\u0012\n",
      "xk −1\n",
      "L∇f (xk)\n",
      "\u0013\n",
      "⩽ˆ\n",
      "f (xk)\n",
      "在式(11.10) 推导中有f(x) ⩽ˆ\n",
      "f(x) 恒成立, 因此, 以下不等式肯定成立:\n",
      "f\n",
      "\u0012\n",
      "xk −1\n",
      "L∇f (xk)\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      " 0 与假设矛盾；b. 假设\n",
      "xi > 0，则sign(xi) = 1，那么有xi = zi −λ\n",
      "L > 0 和假设相符和，下面来检验xi = zi −λ\n",
      "L 是否是使\n",
      "函数g(xi) 的取得最小值\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "和样本xi 的原始\n",
      "表示尽量相似，如果满足这个条件，那么稀疏表示αi 是比较好的。后面的1 范数项是为了使表示更加稀\n",
      "疏。\n",
      "11.4.2\n",
      "式(11.16) 的解释\n",
      "为了优化11.15，我们采用变量交替\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "·\n",
      "h\n",
      "αj\n",
      "1\n",
      "αj\n",
      "2\n",
      "·\n",
      "·\n",
      "·\n",
      "αj\n",
      "m\n",
      "i\n",
      "=\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "b1\n",
      "jαj\n",
      "1\n",
      "b1\n",
      "jαj\n",
      "2\n",
      "·\n",
      "·\n",
      "·\n",
      "b1\n",
      "jαj\n",
      "m\n",
      "b2\n",
      "j\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "), 稀疏系数用xi 表示(书中用αi ), 数据集用Y 表示(书中用X)。\n",
      "图11-1 K-SVD 算法在论文中的描述\n",
      "在初始化字典矩阵D 以后, K-SVD 算法迭代过程分两步: 第1 步Spar\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "1, V1 分别为U, V 的第\n",
      "1 列, 此时dk = U1, xk\n",
      "T = ∆(1, 1)V⊤\n",
      "1 。但这样更新会破坏第1 步中得到的稀疏系数的稀疏性!\n",
      "为了保证第1 步中得到的稀疏系数的稀疏性,\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "据分析结果指导算法设计。例如，\n",
      "“西瓜书”定理12.1、定理12.3、定理12.6 所表达意思的共同点是，\n",
      "泛化误差与经验误差之差的绝对值以很大概率(1 −δ) 很小，且这个差的绝对值随着训练样本个数\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "e., ⩽) e−2mϵ2; 式(12.6) 的事\n",
      "件\n",
      "\f",
      "\n",
      "\f",
      " 1\n",
      "m\n",
      "Pm\n",
      "i=1 xi −1\n",
      "m\n",
      "Pm\n",
      "i=1 E (xi)\n",
      "\f",
      "\n",
      "\f",
      " ⩾ϵ 等价于以下事件:\n",
      "1\n",
      "m\n",
      "m\n",
      "X\n",
      "i=1\n",
      "xi −1\n",
      "m\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "2.3）\n",
      "• 需多少训练样例才能获得较好的模型？\n",
      "（定义12.4）\n",
      "有限假设空间指H 中包含的假设个数是有限的, 反之则为无限假设空间; 无限假设空间更为常见, 例\n",
      "如能够将图5.4(a)(b)(c)\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "0) 就是这些互斥事件之和，\n",
      "即\n",
      "P\n",
      "\u0010\n",
      "h ∈H : E(h) > ϵ ∧b\n",
      "E(h) = 0\n",
      "\u0011\n",
      "=\n",
      "|H|\n",
      "X\n",
      "i\n",
      "P\n",
      "\u0010\n",
      "E(hi) > ϵ ∧b\n",
      "E(hi) = 0\n",
      "\u0011\n",
      "< |H|(1 −ϵ\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      ")\n",
      "P(|E(h) −b\n",
      "E(h)| ⩾ϵ) ⩽2 exp\n",
      "\u0000−2mϵ2\u0001\n",
      "P(|E(h) −b\n",
      "E(h)| ⩾ϵ) ⩽δ\n",
      "P(|E(h) −b\n",
      "E(h)| ⩽ϵ) ⩾1 −δ\n",
      "P(−ϵ ⩽E(h) \n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "2.21) 的解释\n",
      "这个是增长函数的定义式。增长函数ΠH(m) 表示假设空间H 对m 个样本所能赋予标签的最大可能\n",
      "的结果数。比如对于两个样本的二分类问题，一共有4 中可能的标签组合[[0, 0], \n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "成立”，当m = 1, d = 0 时，\n",
      "由VC 维的定义(式12.23) VC(H) = max {m : ΠH(m) = 2m} = 0 可知ΠH(1) < 2，否则d 可以取到1，\n",
      "又因为ΠH(\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "1 −i)!i! +\n",
      "(m −1)!\n",
      "(m −1 −i + 1)!(i −1)!\n",
      "=\n",
      "(m −1)!(m −i)\n",
      "(m −i)(m −1 −i)!i! +\n",
      "(m −1)!i\n",
      "(m −i)!(i −1)\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "4.8\n",
      "定理12.4 的解释\n",
      "首先回忆PAC 可学习的概念，见定义12.2，而可知/不可知PAC 可学习之间的区别仅仅在于概念类\n",
      "c 是否包含于假设空间H 中。令\n",
      "δ′ = δ\n",
      "2\n",
      "r\n",
      "(ln 2/δ\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "demacher 复\n",
      "杂度则在一定程度上考虑了数据分布。\n",
      "12.5.1\n",
      "式(12.36) 的解释\n",
      "这里解释从第一步到第二步的推导，\n",
      "因为前提假设是2 分类问题，\n",
      "yk ∈{−1, +1}，\n",
      "因此I (\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "，\n",
      "很容易理解，\n",
      "因为假设\n",
      "h 即可以看做是作用在数据xi 上的一个映射，\n",
      "通过这个映射可以得到标签yi。\n",
      "注意前提假设实值函数空间\n",
      "F : Z →R，即映射f 将样本zi 映射到了实数空间，这个时候\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "[f] −b\n",
      "EZ(f)\n",
      "\u0011\u0015\n",
      "= EZ\n",
      "\u0014\n",
      "sup\n",
      "f∈F\n",
      "EZ′\n",
      "h\n",
      "b\n",
      "EZ′(f) −b\n",
      "EZ(f)\n",
      "i\u0015\n",
      "⩽EZ,Z′\n",
      "\u0014\n",
      "sup\n",
      "f∈F\n",
      "\u0010\n",
      "b\n",
      "EZ′(f) −b\n",
      "EZ(f)\n",
      "\u0011\u0015\n",
      "= \n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "的特殊情况, 得到了比定理12.5 更紧的泛化误差界, 仅此而已。\n",
      "下面做一些证明：\n",
      "(1) 首先通过式(12.49) 将值域为{−1, +1} 的假设空间H 转化为值域为[0, 1] 的函数空间FH\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "记之间的差别”\n",
      "，这里针\n",
      "对的是二分类，预测标记和真实标记均只能取和两个值，它们之间的“差别”又能是什么呢？\n",
      "因此，当“差别”取为时，式(12.54) 的泛化损失就是式(12.1) 的泛化误差，式(1\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "p\n",
      "\u0010\n",
      "−2m (ϵ′)2\u0011\n",
      "可以解得m =\n",
      "2\n",
      "ϵ2 ln 4\n",
      "δ，由Hoeffding 不等式12.6，\n",
      "P\n",
      " \f",
      "\n",
      "\f",
      "\n",
      "\f",
      "\n",
      "\f",
      "\n",
      "\f",
      "\n",
      "1\n",
      "m\n",
      "m\n",
      "X\n",
      "i=1\n",
      "xi −1\n",
      "m\n",
      "m\n",
      "X\n",
      "i=1\n",
      "E (x\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "带来的好处; 图13.2 对比\n",
      "了主动学习、(纯) 半监督学习和直推学习, 尤其是巧妙地将主动学习的概念融入进来。\n",
      "直推学习是综合运用手头上已有的少量有标记样本和大量末标记样本, 对这些大量末标记样本\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "\n",
      "1,\n",
      "i = j\n",
      "0,\n",
      "i ̸= j\n",
      "13.2.3\n",
      "式(13.3) 的推导\n",
      "根据式(13.1)\n",
      "p(x) =\n",
      "N\n",
      "X\n",
      "i=1\n",
      "αi · p (x|µi, Σi)\n",
      "因此\n",
      "p(Θ = i|x) = p\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "=\n",
      "X\n",
      "(xj,yj)∈Dl∧yj=i\n",
      "∂ln (αi · p (xj|µi, Σi))\n",
      "∂µi\n",
      "=\n",
      "X\n",
      "(xj,yj)∈Dl∧yj=i\n",
      "1\n",
      "p (xj|µi, Σi) · ∂p (xj|µi, Σi\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "−1\n",
      "i\n",
      "(xj −µi) (xj −µi)⊤−I\n",
      "\u0011\n",
      "· 1\n",
      "2Σ−1\n",
      "i\n",
      "综合可得：\n",
      "∂LL (Dl ∪Du)\n",
      "∂Σi\n",
      "=\n",
      "X\n",
      "xj∈Du\n",
      "γji ·\n",
      "\u0010\n",
      "Σ−1\n",
      "i\n",
      "(xj −µi) (xj −\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "Dl∧yj=i\n",
      "∂ln (αi · p (xj|µi, Σi))\n",
      "∂αi\n",
      "=\n",
      "X\n",
      "(xj,yj)∈Dl∧yj=i\n",
      "1\n",
      "αi · p (xj|µi, Σi) · ∂(αi · p (xj|µi, Σi)\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "习本节算法，会发现实际很简单；否则会感觉无从下手，难以理解。\n",
      "由本节开篇的两段介绍可知，S3VM 是SVM 在半监督学习上的推广，是此类算法的总称而非某个具\n",
      "体的算法，其最著名的代表是TSVM。\n",
      "13\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "量仍然大于0 , 但至少ξi + ξj 比交换之前变小了;\n",
      "若进一步的, 当ξi, ξj > 2 时, 则交换之后ξi + ξj 将变为0 , 如图13-3所示。\n",
      "交换\n",
      "图13-3 (ξi > 2) \n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "0 < ξi < 1) ∧(ξj > 2)\n",
      "可以发现, 交换之后其中之一被正确分类, ξi + ξj 比交换之前也变小了。综上所述, 当ξi + ξj > 2 时,\n",
      "交换指派标记ˆ\n",
      "yi, ˆ\n",
      "yj \n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "于W 是对称矩阵(即(W)ij = W)ji ), 并交换了求和号次序(类似于多重积分中交换积分号次序),\n",
      "到此完成了该步骤的证明; 第3 个等号是由于f 2 (xi) 与求和变量j 无关, 因此拿到\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "\n",
      "l (Dll −W ll) f l −2f T\n",
      "uW ulf l + f T\n",
      "u (Duu −W uu) f u\n",
      "∂f u\n",
      "= −2W ulf l + 2 (Duu −W uu) f u\n",
      "令结果等于\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "\n",
      "t = 1 : F(2) = αSF(1) + (1 −α)Y = αS(αSY + (1 −α)Y) + (1 −α)Y\n",
      "= (αS)2Y + (1 −α)\n",
      " \n",
      "1\n",
      "X\n",
      "i=0\n",
      "(αS)i\n",
      "!\n",
      "Y\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "m\n",
      "j=1(W)ij = Pm\n",
      "j=1(W)ji （已在式(13.12) 推导时说明）\n",
      "。显然,\n",
      "m\n",
      "X\n",
      "i=1\n",
      "FiF⊤\n",
      "i =\n",
      "m\n",
      "X\n",
      "j=1\n",
      "FjF⊤\n",
      "j =\n",
      "m\n",
      "X\n",
      "i=1\n",
      "∥Fi∥2 = ∥\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "r\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(S)11\n",
      "(S)12\n",
      "· · ·\n",
      "(S)1m\n",
      "(S)21\n",
      "(S)22\n",
      "· · ·\n",
      "(S)2m\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "...\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      ":\n",
      "∂Q(F)\n",
      "∂F\n",
      "= ∂tr\n",
      "\u0000FF⊤\u0001\n",
      "∂F\n",
      "−∂tr\n",
      "\u0000SFF⊤\u0001\n",
      "∂F\n",
      "+ µ∂∥F −Y∥2\n",
      "F\n",
      "∂F\n",
      "= 2F −2SF + 2µ(F −Y)\n",
      "令µ = 1−α\n",
      "α , 并令∂Q(F)\n",
      "\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "ew learning.\n",
      "arXiv preprint\n",
      "arXiv:1304.5634, 2013.\n",
      "→_→\n",
      "配套视频教程：https://www.bilibili.com/video/BV1Mh41\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "条件随机场；接下来两节分别介绍精确推断和近似推断；最后一节简单介绍了话题模型的典型代表\n",
      "隐狄利克雷分配模型(LDA)。\n",
      "14.1\n",
      "隐马尔可夫模型\n",
      "本节前三段内容实际上是本章的概述，\n",
      "从第四段才开始介绍\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "定, 与其它状态变量及观测变量的取值无关。因此\n",
      "P (x1, . . . , xn | y1, . . . , yn) = P (x1 | y1, . . . , yn) · . . . · P (x\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "=1\n",
      "xiyj = x1y1 + x1y2 + x1y3 + x2y1 + x2y2 + x2y3 + x3y1 + x3y2 + x3y3\n",
      "= x1 × (y1 + y2 + y3) + x2 × \n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "10) 中给定变量v 以外的所有变量与仅给定变量v 的邻接变量是等价的。\n",
      "特别注意, 本式下方写到“则(y, x) 构成一个条件随机场”; 也就是说, 因为(y, x) 满足式(14.10), 所\n",
      "以\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      ", 无法类似于P\n",
      "x4 P (x4 | x3) =\n",
      "1 去处理P\n",
      "x4 ψ (x3, x4) 。\n",
      "但根据边际化运算规则，可以知道：\n",
      "m12 (x2) = P\n",
      "x1 ψ12 (x1, x2) 只含x2 \n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "传递消息, 直到根\n",
      "结点收到所有邻接结点的消息; 图(b) 表示信念传播算法的第2 步, 即从根结点开始向叶结点传递消息, 直\n",
      "到所有叶结点均收到消息。\n",
      "本图并不难理解, 接下来思考如下两个问题:\n",
      "【\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "πjTji = πj\n",
      "假设采样得到的序列为x1, x2, .., xt−1, xt，则可以使用MH 算法来使得xt−1(假设为状态si) 转移到xt(假\n",
      "设为状态sj) 的概率满足式。\n",
      "本式为某个时刻\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "第334 页):\n",
      "(1) 随机或以某个次序选取某变量xi;\n",
      "(2) 根据x 中除xi 外的变量的现有取值, 计算条件概率p (xi | x¯\n",
      "i), 其中x¯\n",
      "i = {x1, x2, . . . ,\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "对数, 得:\n",
      "ln p(x) = ln p(x, z)/q(z)\n",
      "p(z | x)/q(z) = ln p(x, z)\n",
      "q(z)\n",
      "−ln p(z | x)\n",
      "q(z)\n",
      "等号两边同时乘以q(z) 并积分,\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      ")dz =\n",
      "Z\n",
      "qj\n",
      "(Z\n",
      "ln p(x, z)\n",
      "M\n",
      "Y\n",
      "i̸=j\n",
      "(qi (zi) dzi)\n",
      ")\n",
      "dzj\n",
      "令ln ˜\n",
      "p (x, zj) =\n",
      "R\n",
      "ln p(x, z) QM\n",
      "i̸=j (qi (zi\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "\n",
      "const, 当然这并没有什么问题, 并不影响式(14.36) 本身。具体来说, 将本项反代回式(14.36) 第二个等号\n",
      "右侧第1 项, 即:\n",
      "Z\n",
      "qj\n",
      "(Z\n",
      "ln p(x, z)\n",
      "M\n",
      "Y\n",
      "i̸=\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "const )\n",
      "=\n",
      "exp (Ei̸=j[ln p(x, z)])\n",
      "R\n",
      "exp (Ei̸=j[ln p(x, z)]) dzj\n",
      "实际上, 本式的分母为归一化因子, 以保证q∗\n",
      "j (zj) 为概率分布\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "“如果A 或B，并且C 的条件下，D 满足”这样的形式。因为这种学习方法更加贴合人类从数\n",
      "据中学到经验的描述，具有非常良好的可解释性，是最早开始研究机器学习的技术之一。\n",
      "15.1\n",
      "剪枝优化\n",
      "15.1.\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "字，构造新的逻辑子句和文字的\n",
      "关系。在式(15.11) 中，已知p ←A ∧B 和p ←A ∧q，构造的新逻辑文字为q ←B。\n",
      "15.2.6\n",
      "式(15.12) 的解释\n",
      "该式是内构(intra-cons\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "”该章内容仅可作为综述查阅，若想深究建议查阅其他相关书籍（例如《Easy RL：强化\n",
      "学习教程》\n",
      "[1]）进行系统性学习。\n",
      "16.1\n",
      "任务与奖赏\n",
      "本节理解强化学习的定义和相关术语的含义即可。\n",
      "16.2\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      ".3.2\n",
      "式(16.8) 的推导\n",
      "V π\n",
      "γ (x) = Eπ[\n",
      "∞\n",
      "X\n",
      "t=0\n",
      "γtrt+1 | x0 = x]\n",
      "= Eπ[r1 +\n",
      "∞\n",
      "X\n",
      "t=1\n",
      "γtrt+1 | x0 = x]\n",
      "= Eπ[r1\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "=\n",
      "X\n",
      "x′∈X\n",
      "P π′(x′)\n",
      "x′→x′(Rπ′(x′)\n",
      "x′→x′ + γV π(x′))\n",
      "于是，当前状态的最优值函数为\n",
      "V ∗(x) = V π′(x) ⩾V π(x)\n",
      "16.4\n",
      "免模型学习\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "\n",
      "= ∂θTx\n",
      "∂θ\n",
      "=\n",
      "\"\n",
      "∂θTx\n",
      "∂θ1\n",
      ", ∂θTx\n",
      "∂θ2\n",
      ", · · · , ∂θTx\n",
      "∂θn\n",
      "#T\n",
      "= [x1, x2, · · · , xm]T\n",
      "= x\n",
      "故\n",
      "−∂Eθ\n",
      "∂θ = Ex∼\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "or Developer》课程是由吴恩达老师与 OpenAI 技术团队成员 Isa Fulford 老师合作授课，Isa 老师曾开发过受欢迎的 ChatGPT 检索插件，并且在教授 LLM （Larg\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "rompt 的两个关键原则：编写清晰、具体的指令和给予模型充足思考时间。掌握这两点，对创建可靠的语言模型交互尤为重要。\n",
      "\n",
      "首先，Prompt 需要清晰明确地表达需求，提供充足上下文，使语言模型准确理解\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "功率可能更高，但仍需要通过多次迭代找到最适合应用的形式。\n",
      "\n",
      "本章以产品说明书生成营销文案为例，展示 Prompt 迭代优化的思路。这与吴恩达在机器学习课程中演示的机器学习模型开发流程相似：有了想法后，\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "语言模型（LLM）的文本摘要功能。\n",
      "\n",
      "这个功能对小明来说如同灯塔一样，照亮了他处理信息海洋的道路。LLM 的强大能力在于它可以将复杂的文本信息简化，提炼出关键的观点，这对于他来说无疑是巨大的帮助。他不\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "的情感和主题。这些任务包括了标签提取、实体提取、以及理解文本的情感等等。在传统的机器学习流程中，你需要收集标签化的数据集、训练模型、确定如何在云端部署模型并进行推断。尽管这种方式可能会产生不错的效果，\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "通过编程调用API接口，使用语言模型实现文本转换功能。通过代码示例，读者可以学习将输入文本转换成所需输出格式的具体方法。\n",
      "\n",
      "掌握调用大语言模型接口进行文本转换的技能，是开发各种语言类应用的重要一步。文\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "在本章中,我们将学习基于 OpenAI API 实现一个客户邮件自动生成的示例，用于根据客户反馈优化客服邮件。这里还会介绍“温度”（temperature）这一超参数，它可以控制文本生成的多样性。\n",
      "\n",
      "\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "有个性化特性（或专门为特定任务或行为设计）的聊天机器人进行深度对话。\n",
      "\n",
      "像 ChatGPT 这样的聊天模型实际上是组装成以一系列消息作为输入，并返回一个模型生成的消息作为输出的。这种聊天格式原本的设计\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "还学习了迭代式 Prompt 开发的方法，并了解了如何找到适合您应用程序的 Prompt 的过程是非常关键的。\n",
      "\n",
      "我们还讨论了大型语言模型的许多功能，包括摘要、推断、转换和扩展。您也学习了如何搭建个性\n",
      "-----------------\n",
      "类型：<class 'langchain_core.documents.base.Document'>\n",
      " 查看该文档的内容：\n",
      "交互输入的代称。即我们一般将给大模型的输入称为 Prompt，将大模型返回的输出称为 Completion。\n",
      "\n",
      "随着 ChatGPT 等 LLM（大语言模型）的出现，自然语言处理的范式正在由 Pret\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders.pdf import PyMuPDFLoader\n",
    "from langchain.document_loaders.markdown import UnstructuredMarkdownLoader\n",
    "\n",
    "# 遍历路径将实例化的loader存放到loaders\n",
    "loaders = []\n",
    "for file_path in file_paths:\n",
    "    file_type = file_path.split('.')[-1]\n",
    "    if file_type == 'pdf':\n",
    "        loaders.append(PyMuPDFLoader(file_path))\n",
    "    elif file_type == 'md':\n",
    "        loaders.append(UnstructuredMarkdownLoader(file_path))\n",
    "loaders\n",
    "texts = []\n",
    "for loader in loaders: texts.extend(loader.load())\n",
    "for text in texts:\n",
    "    print(f\"类型：{type(text)}\\n\",\n",
    "#            f\"该文档的描述性内容：{text.metadata}\\n\",\n",
    "           f\"查看该文档的内容：\\n{text.page_content[100:200]}\")\n",
    "    print(\"-----------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "82c1c586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "print(len(loaders))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08b063cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "934"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# cut\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,chunk_overlap=50\n",
    ")\n",
    "\n",
    "split_docs = text_splitter.split_documents(texts)\n",
    "len(split_docs) # 最终有这么多个片段"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f84535",
   "metadata": {},
   "source": [
    "# create vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02951670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function is about to be called\n",
      "hello Brian\n",
      "function has been called\n"
     ]
    }
   ],
   "source": [
    "# learning decorator\n",
    "def simple_decorator(func):\n",
    "    def wrapper(*args,**kwargs):\n",
    "        # *args: 接收任意数量的位置参数，并将其存储为一个元组\n",
    "        # ** kwargs:接收任意数量的关键字参数，并将其存储为一个字典\n",
    "        # 在定义函数时候，不清楚会传入几个参数或者关键字参数，可以使用上述两个，更加灵活\n",
    "        print(\"function is about to be called\")\n",
    "        func(*args,**kwargs)\n",
    "        print(\"function has been called\")\n",
    "    return wrapper\n",
    "\n",
    "@simple_decorator\n",
    "def say_hello(name):\n",
    "    print(f\"hello {name}\")\n",
    "\n",
    "say_hello(\"Brian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "602bb361",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import logging\n",
    "from typing import Dict,List,Any\n",
    "\n",
    "from langchain.embeddings.base import Embeddings\n",
    "from langchain.pydantic_v1 import BaseModel, root_validator\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69093e0",
   "metadata": {},
   "source": [
    "## 自定义Embedding类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "86237da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbconvert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "94959fbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook zhipuai_embedding.ipynb to script\n",
      "[NbConvertApp] Writing 2354 bytes to zhipuai_embedding.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script zhipuai_embedding.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd0402dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import zhipuai_embedding\n",
    "from zhipuai_embedding import ZhipuAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "821b7cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = ZhipuAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f20b7c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义持久化路径\n",
    "persist_directory = '../LLM/data_base/vector_db/chroma'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00016fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'rm' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!rm -rf '../../data_base/vector_db/chroma'  # 删除旧的数据库文件（如果文件夹中有文件的话），windows电脑请手动删除"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e811ab",
   "metadata": {},
   "source": [
    "## create vector_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f9d96f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores.chroma import Chroma\n",
    "import chromadb\n",
    "# 该类用于创建一个向量数据库，用于存储和检索文档的embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b2f76e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(\n",
    "    # 该方法创建一个chroma向量数据库，并将生成的数据持久化到指定目录\n",
    "    documents = split_docs[:20], # 取前20个片段\n",
    "    embedding=embedding,\n",
    "    persist_directory=persist_directory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3f71dfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a77e14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "向量库中存储的数量：40\n"
     ]
    }
   ],
   "source": [
    "print(f\"向量库中存储的数量：{vectordb._collection.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3f5711",
   "metadata": {},
   "source": [
    "# 向量检索"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff76d24",
   "metadata": {},
   "source": [
    "## 相似度检索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b3a8c6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "检索到的内容数为： 4\n"
     ]
    }
   ],
   "source": [
    "question = \"什么是提示词工程\"\n",
    "sim_docs = vectordb.similarity_search(question, k = 4)\n",
    "print(\"检索到的内容数为：\",len(sim_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "18d8b11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "检索到的第0个内容：第一章 简介\n",
      "\n",
      "作者 吴恩达教授\n",
      "\n",
      "欢迎来到本课程，我们将为开发人员介绍 ChatGPT 提示词工程（Prompt Engineering）。本课程由 Isa Fulford 教授和我一起授课。Isa 是 OpenAI 的技术团队成员，曾开发过受欢迎的 ChatGPT 检索插件，并且在教授 LLM （Large Language Model, 大语言模型）技术在产品中的应用方面做出了很大贡献。她还\n",
      "----------------\n",
      "检索到的第1个内容：第一章 简介\n",
      "\n",
      "作者 吴恩达教授\n",
      "\n",
      "欢迎来到本课程，我们将为开发人员介绍 ChatGPT 提示词工程（Prompt Engineering）。本课程由 Isa Fulford 教授和我一起授课。Isa 是 OpenAI 的技术团队成员，曾开发过受欢迎的 ChatGPT 检索插件，并且在教授 LLM （Large Language Model, 大语言模型）技术在产品中的应用方面做出了很大贡献。她还\n",
      "----------------\n",
      "检索到的第2个内容：互联网上有很多有关提示词（Prompt, 本教程中将保留该术语）的材料，例如《30 prompts everyone has to know》之类的文章。这些文章主要集中在 ChatGPT 的 Web 界面上，许多人在使用它执行特定的、通常是一次性的任务。但是，我认为对于开发人员，LLM 的更强大功能是能通过 API 调用，从而快速构建软件应用程序。我认为这方面还没有得到充分的重视。实际上，我们在\n",
      "----------------\n",
      "检索到的第3个内容：互联网上有很多有关提示词（Prompt, 本教程中将保留该术语）的材料，例如《30 prompts everyone has to know》之类的文章。这些文章主要集中在 ChatGPT 的 Web 界面上，许多人在使用它执行特定的、通常是一次性的任务。但是，我认为对于开发人员，LLM 的更强大功能是能通过 API 调用，从而快速构建软件应用程序。我认为这方面还没有得到充分的重视。实际上，我们在\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "for i, docs in enumerate(sim_docs):\n",
    "    print(f\"检索到的第{i}个内容：{docs.page_content[:200]}\", end=\"\\n----------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "456526e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMR检索到的第0个内容：\n",
      "第一章 简介\n",
      "\n",
      "作者 吴恩达教授\n",
      "\n",
      "欢迎来到本课程，我们将为开发人员介绍 ChatGPT 提示词工程（Prompt Engineering）。本课程由 Isa Fulford 教授和我一起授课。Isa 是 OpenAI 的技术团队成员，曾开发过受欢迎的 ChatGPT 检索插件，并且在教授 LLM （Large Language Model, 大语言模型）技术在产品中的应用方面做出了很大贡献。她还\n",
      "---------------\n",
      "MMR检索到的第1个内容：\n",
      "当您使用指令微调 LLM 时，您可以类比为向另一个人提供指令（假设他很聪明但不知道您任务的具体细节）。因此，当 LLM 无法正常工作时，有时是因为指令不够清晰。例如，如果您想问“请为我写一些关于阿兰·图灵( Alan Turing )的东西”，在此基础上清楚表明您希望文本专注于他的科学工作、个人生活、历史角色或其他方面可能会更有帮助。另外您还可以指定回答的语调, 来更加满足您的需求，可选项包括专业\n",
      "---------------\n",
      "MMR检索到的第2个内容：\n",
      "前言\n",
      "“周志华老师的《机器学习》\n",
      "（西瓜书）是机器学习领域的经典入门教材之一，周老师为了使尽可能多的读\n",
      "者通过西瓜书对机器学习有所了解, 所以在书中对部分公式的推导细节没有详述，但是这对那些想深究公式推\n",
      "导细节的读者来说可能“不太友好”\n",
      "，本书旨在对西瓜书里比较难理解的公式加以解析，以及对部分公式补充\n",
      "具体的推导细节。\n",
      "”\n",
      "读到这里，大家可能会疑问为啥前面这段话加了引号，因为这只是我们最初的遐想，\n",
      "---------------\n",
      "MMR检索到的第3个内容：\n",
      "9\n",
      "2.3.10 式(2.23) 的解释\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "10\n",
      "2.3.11 式(2.24) 的解释\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "11\n",
      "2.3.12\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "mmr_docs = vectordb.max_marginal_relevance_search(question, k=4)\n",
    "for i,sim_doc in enumerate(mmr_docs):\n",
    "    print(f\"MMR检索到的第{i}个内容：\\n{sim_doc.page_content[:200]}\",end = \"\\n---------------\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:AFT_new]",
   "language": "python",
   "name": "conda-env-AFT_new-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
