{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8eb8ec70",
   "metadata": {},
   "source": [
    "# Using Chatgpt based on Langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6c663f",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f4caf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv,find_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25d51433",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff4671e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取环境变量openai_api_key\n",
    "openai_api_key = os.environ['OPENAI_API_KEY']\n",
    "# 包含API服务器基本地址的URL，制定了你用来发送请求的API服务器地址，当建立一个API\n",
    "# 客户端的时候，所有的请求都会send到这个url\n",
    "base_url = os.environ['BASE_URL']\n",
    "# 总之\n",
    "# api_key决定是否允许这个请求以及以什么级别进行访问\n",
    "# base_url则决定了请求发送到哪个服务器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1d6e508",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09e1cd1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x000001D6C6BEF130>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x000001D6C6C1CCA0>, temperature=0.0, openai_api_key=SecretStr('**********'), openai_api_base='https://api.chatanywhere.tech/v1', openai_proxy='')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOpenAI(temperature=0.0,openai_api_key=openai_api_key,\n",
    "                base_url=base_url)\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "323acd9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = llm.invoke(\"do you know what means large-language-model\")\n",
    "type(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f2dc0c",
   "metadata": {},
   "source": [
    "## prompt\n",
    "开发大模型应用时候，通常不会直接将用户的输入直接传递给LLM。\n",
    "需要用到提示模板：它捆绑了从用户输入转换成完全格式化的提示的所有逻辑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ea539ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d164c58b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hi,Brian.the question your asked is: how to use langchain, the answer I provided is as followed:'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "# 定义一个提示模板\n",
    "template  = PromptTemplate(\n",
    "    input_variables = [\"name\",\"question\"],\n",
    "    template = \"hi,{name}.the question your asked is: {question}, the answer I provided is as followed:\"\n",
    ")\n",
    "# 定义模板中所需要填充的变量\n",
    "variables = {\n",
    "    \"name\":\"Brian\",\n",
    "    \"question\":\"how to use langchain\"\n",
    "}\n",
    "# 渲染模板，生成最终得提示\n",
    "final_prompt = template.format(**variables)\n",
    "final_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e74f72c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "# we ask the model to translate the texts we give to chinese\n",
    "prompt = \"\"\"请你将由三个反引号分割的文本翻译成英文！\\\n",
    "text:'''{text}'''\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "853431b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"请你将由三个反引号分割的文本翻译成英文！text:'''我带着比身体重的行李，游入尼罗河底，经过几道闪电 看到一堆光圈，不确定是不是这里。'''\\n\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"我带着比身体重的行李，\\\n",
    "游入尼罗河底，\\\n",
    "经过几道闪电 看到一堆光圈，\\\n",
    "不确定是不是这里。\\\n",
    "\"\n",
    "# 构造完整的提示词模板\n",
    "prompt.format(text=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cbe590ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='you are an agent, you can help me to translate Chinese into English'),\n",
       " HumanMessage(content='我带着比身体重的行李，游入尼罗河底，经过几道闪电 看到一堆光圈，不确定是不是这里。')]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 通常而言，一个ChatMessageTemplate 是一个ChatMessageTemplate的列表。\n",
    "# 每个ChatMessageTemplate包含格式化聊天消息的说明（角色以及其内容）\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "template = \"you are an agent, you can help me to translate {input_lan} into {output_lan}\"\n",
    "human_template = \"{text}\"\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",template),\n",
    "    (\"human\",human_template)\n",
    "])\n",
    "\n",
    "messages = chat_prompt.format_messages(input_lan = \"Chinese\", output_lan = \"English\",text=text)\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "94d2c195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I carried luggage heavier than my body and waded into the bottom of the Nile. After a few flashes of lightning, I saw a pile of halos, not sure if this is the place.', response_metadata={'token_usage': {'completion_tokens': 40, 'prompt_tokens': 78, 'total_tokens': 118}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_2f57f81c11', 'finish_reason': 'stop', 'logprobs': None}, id='run-84c28910-02c2-4dab-a3de-0d4004577248-0', usage_metadata={'input_tokens': 78, 'output_tokens': 40, 'total_tokens': 118})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = llm.invoke(messages)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954898c2",
   "metadata": {},
   "source": [
    "## 输出解析器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e0e47608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I carried luggage heavier than my body and waded into the bottom of the Nile. After a few flashes of lightning, I saw a pile of halos, not sure if this is the place.'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()\n",
    "output = output_parser.invoke(output)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609f1431",
   "metadata": {},
   "source": [
    "## complete process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805e25ca",
   "metadata": {},
   "source": [
    "将上述所有的步骤组合成一条链，该链：\n",
    "1.获取输入变量\n",
    "2.将这些变量传递给提示模板以创建提示，将提示传递给语言模型\n",
    "3.通过输出解析器传递输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a231253a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I carried luggage heavier than my body and waded into the bottom of the Nile River. After passing through several flashes of lightning, I saw a pile of halos, unsure if this is the place.'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = chat_prompt | llm | output_parser\n",
    "chain.invoke({\"input_lan\":\"Chinese\",\"output_lan\":\"English\",\"text\":text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7bacaae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'我扛着比我的身体还要重的行李，涉入了尼罗河的深处。穿过几道闪电后，我看到了一堆光环，不确定这是否就是目的地。'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'I carried luggage heavier than my body and waded into the bottom of the Nile River. After passing through several flashes of lightning, I saw a pile of halos, unsure if this is the place.'\n",
    "chain.invoke({\"input_lan\":\"English\",\"output_lan\":\"Chinese\",\"text\":text})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9446db",
   "metadata": {},
   "source": [
    "# Using wenxin(QIANFAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3fd4d667",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import find_dotenv, load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e988360d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fa8d0ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3bXSuko4LWd4QW2Bdf8tQsWA\n",
      "------------\n",
      "vtNKZdQYs5xObTbQCGESdAm1CYyVyxYv\n"
     ]
    }
   ],
   "source": [
    "QIANFAN_AK = os.environ[\"QIANFAN_AK\"]\n",
    "QIANFAN_SK = os.environ[\"QIANFAN_SK\"]\n",
    "print(QIANFAN_AK,QIANFAN_SK,sep=\"\\n------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cbfd8ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8f439553",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import QianfanLLMEndpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9795338f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm glad to see you too. Thank you for your positive feedback. I will continue to work hard to provide you with better services. If you have any suggestions or problems, please feel free to tell me. I will do my best to solve them.\""
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = QianfanLLMEndpoint(streaming = True)\n",
    "res = llm(\"really nice to see you\")\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3939d07",
   "metadata": {},
   "source": [
    "# Using SPARK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "eb583be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = load_dotenv(find_dotenv())\n",
    "IFLYTEK_SPARK_APP_ID = os.environ[\"IFLYTEK_SPARK_APP_ID\"]\n",
    "IFLYTEK_SPARK_API_KEY = os.environ[\"IFLYTEK_SPARK_API_KEY\"]\n",
    "IFLYTEK_SPARK_API_SECRET = os.environ[\"IFLYTEK_SPARK_API_SECRET\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e11ec4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_spark_params(model):\n",
    "    \"\"\"\n",
    "    构造星火模型请求参数\n",
    "    \"\"\"\n",
    "    spark_url_tpl = \"wss://spark-api.xf-yun.com/{}/chat\"\n",
    "    model_params_dict = {\n",
    "        \"v1.5\": {\n",
    "            \"domain\": \"general\", # 用于配置大模型版本\n",
    "            \"spark_url\": spark_url_tpl.format(\"v1.1\") # 云端环境的服务地址\n",
    "        },\n",
    "        # v2.0 版本\n",
    "        \"v2.0\": {\n",
    "            \"domain\": \"generalv2\", # 用于配置大模型版本\n",
    "            \"spark_url\": spark_url_tpl.format(\"v2.1\") # 云端环境的服务地址\n",
    "        },\n",
    "        # v3.0 版本\n",
    "        \"v3.0\": {\n",
    "            \"domain\": \"generalv3\", # 用于配置大模型版本\n",
    "            \"spark_url\": spark_url_tpl.format(\"v3.1\") # 云端环境的服务地址\n",
    "        },\n",
    "        # v3.5 版本\n",
    "        \"v3.5\": {\n",
    "            \"domain\": \"generalv3.5\", # 用于配置大模型版本\n",
    "            \"spark_url\": spark_url_tpl.format(\"v3.5\") # 云端环境的服务地址\n",
    "        }\n",
    "    }\n",
    "    return model_params_dict[model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "95315880",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import SparkLLM\n",
    "spark_api_url = gen_spark_params(model=\"v3.5\")[\"spark_url\"]\n",
    "llm = SparkLLM(spark_api_url = spark_api_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "faea41c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! I am iFLYTEK Spark, and I can provide you with various cognitive intelligence services including language understanding, question and answer, reasoning and so on through natural language interaction.'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = llm(\"hi,please introduce yourself\")\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7472fe2",
   "metadata": {},
   "source": [
    "# Using ChatGLM3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d28b7ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zhipuai_llm import ZhipuAILLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "abf93f0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'32b0876eda94b85d1d0081eafb5aad2e.1tUeCGG9ElLcJiAO'"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_key = os.environ[\"ZHIPUAI_API_KEY\"]\n",
    "api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "fc6bf470",
   "metadata": {},
   "outputs": [],
   "source": [
    "zhipuai_model = ZhipuAILLM(model = 'glm-4',temperature=0, api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "4f939c3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'智谱AI的张鹏是该公司的首席执行官。根据提供的参考信息，张鹏在人工智能领域具有深刻的见解和丰富的经验。他强调人工智能的发展对于各行各业的重要性，并认为大模型技术将在其中扮演核心角色。\\n\\n张鹏关注于推动大模型的终端侧应用研发，并致力于提升人机交互能力。他认为，随着AI技术向终端下沉，智能化的体验将变得更加触手可及。在他的领导下，智谱AI专注于打造新一代认知智能大模型，并实现了大模型生成式AI的全链路自主可控。\\n\\n张鹏还曾提到，智谱AI研发的新一代基座大模型GLM-4在中文能力上可以比肩GPT-4，展示了公司在技术上的实力和进步。此外，他提倡开源生态的繁荣，并计划为大模型开源基金提供支持。\\n\\n在人工智能的发展阶段上，张鹏将其分为三个阶段：符号AI、感知智能和认知智能。他认为当前正处于认知智能阶段，关注的是认知的可计算性。张鹏还提出了“2024年是AGI元年”的观点，意味着人工智能正进入一个全新的通用人工智能时代。\\n\\n作为公司的领导者，张鹏强调智谱AI将继续与终端侧产业伙伴合作，开拓新的商用AI终端应用，为各行各业带来数字化和智能化的先进工具。通过他的领导和远见，智谱AI在人工智能领域不断探索和创新。'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zhipuai_model(\"请介绍一下智谱AI的张鹏\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:AFT_new]",
   "language": "python",
   "name": "conda-env-AFT_new-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
